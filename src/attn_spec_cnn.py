#!/usr/bin/env python
# attn_spec_cnn_fixed.py
# ---------------------------------------------------------------
# 1. 64-ch â†’ å»æ‰ EOG â†’ 60-ch
# 2. 2-comp CSP ç²—æ’åˆ†æ•°             ï¼ˆ|w_max|+|w_min|ï¼‰
# 3. SE-Attention-CNN ç»†è°ƒé€šé“æƒé‡   ï¼ˆè®­ç»ƒæ—¶å¯è§‚æµ‹æ³¨æ„åŠ›ï¼‰
# 4. å¯¹ 4-40 Hz ç‰‡æ®µåš STFT â†’ log-power é¢‘è°±å›¾
# 5. GroupKFold(10) é€ trial æŠ•ç¥¨ç²¾åº¦æ›²çº¿
# ---------------------------------------------------------------

import re, math, numpy as np, torch, torch.nn as nn
from pathlib import Path
from scipy.io import loadmat
from scipy.signal import butter, filtfilt, iirnotch, stft
from mne.decoding import CSP
from sklearn.model_selection import GroupKFold
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings("ignore", category=RuntimeWarning)

# ========= è¿è¡Œç¯å¢ƒ & éšæœºç§å­ =========
SEED = 0
np.random.seed(SEED);  torch.manual_seed(SEED)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ’» device = {DEVICE}")

# ========= æ•°æ®è·¯å¾„ =========
ROOT     = Path(__file__).resolve().parent.parent
DATA_DIR = ROOT / "data" / "Short_Long_words"
MAT_FILE = sorted(f for f in DATA_DIR.glob("*.mat") if "_8s" not in f.name)

# ========= é€šé“åå­— (64) =========
ALL_CH_NAMES = [
    # â†“è¯·æ›¿æ¢æˆä½ çœŸå®çš„ 64 é€šé“é¡ºåº
    'Fp1','Fp2','F7','F3','Fz','F4','F8','FC5',
    'FC1','FCz','FC2','FC6','T7','C3','Cz','C4',
    'T8','CP5','CP1','CP2','CP6','P7','P3','Pz',
    'P4','P8','O1','Oz','O2','PO7','PO3','PO4',
    'PO8','AF7','AF3','AF4','AF8','FT7','FT8','TP7',
    'TP8','CP3','CP4','C1','C2','P1','P2','CPz',
    'POz','FC3','FC4','F1','F2','F5','F6','C5',
    'C6','P5','P6','O9','O10','T9','T10','Iz'
]
assert len(ALL_CH_NAMES) == 64, "ALL_CH_NAMES å¿…é¡»æ­£å¥½ 64 ä¸ªï¼"

# â†’ è¦å‰”é™¤çš„ 4 ä¸ª EOG / reference ç´¢å¼•
EOG_IDX = {0, 9, 32, 63}
KEEP_CH_ID = [i for i in range(64) if i not in EOG_IDX]
CHAN_NAMES = [ALL_CH_NAMES[i] for i in KEEP_CH_ID]
print("ä¿ç•™é€šé“æ•° =", len(KEEP_CH_ID))                       # åº”ä¸º 60

# ========= ä¿¡å·å¤„ç†å‚æ•° =========
FS       = 256
WIN_S    = 2.0;   WIN  = int(WIN_S * FS)      # 2-s ç‰‡æ®µ
STEP_S   = 0.5;   STEP = int(STEP_S * FS)
K_LIST   = [4, 8, 16, 32, 60]
EPOCHS   = 120
BATCH    = 128

# ========= é¢„å¤„ç†æ»¤æ³¢å™¨ =========
bp_b, bp_a = butter(4, [4, 40], fs=FS, btype='band')
nt_b, nt_a = iirnotch(60, 30, fs=FS)

def preprocess(raw):
    """
    raw : (C,T) float64/float32
    return: (C,T) float32, å·²å¸¦é€šã€é™·æ³¢ã€æ ‡å‡†åŒ–
    """
    x = raw.astype(np.float32, copy=False)
    x = filtfilt(nt_b, nt_a, x, axis=1)
    x = filtfilt(bp_b, bp_a, x, axis=1)
    x -= x.mean(axis=1, keepdims=True)
    x /= x.std (axis=1, keepdims=True) + 1e-6
    return x

def slide(sig_k):
    """(K,T) â†’ (n_win, K, T_win)"""
    wins = [sig_k[:, st:st+WIN]
            for st in range(0, sig_k.shape[1]-WIN+1, STEP)]
    return np.stack(wins)

def to_spec(win):
    """(K,T_win) â†’ (K,F,T')  log-power STFT"""
    spec = []
    for ch in win:
        f, t, Z = stft(ch, fs=FS, window='hann',
                       nperseg=128, noverlap=64)
        spec.append(np.log1p(np.abs(Z)))
    return np.stack(spec)                      # (K, F, T')

# ========= æ³¨æ„åŠ› CNN =========
class SE_Block(nn.Module):
    def __init__(self, c, r=4):
        super().__init__()
        self.gap = nn.AdaptiveAvgPool2d(1)
        self.fc  = nn.Sequential(
            nn.Linear(c, c//r, bias=False), nn.ReLU(),
            nn.Linear(c//r, c, bias=False), nn.Sigmoid())
    def forward(self, x):
        y = self.gap(x).flatten(1)             # (B,C)
        w = self.fc(y).view(x.size(0), x.size(1), 1, 1)
        return x * w, w                        # è¿”å›æ³¨æ„åŠ›æƒé‡

class SpecCNN(nn.Module):
    def __init__(self, img_h, img_w):          # h = K*F , w = T'
        super().__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)
        self.bn1   = nn.BatchNorm2d(16)
        self.se1   = SE_Block(16)
        self.pool1 = nn.MaxPool2d(2)
        self.drop1 = nn.Dropout(.25)

        h2 = img_h // 2
        w2 = img_w // 2
        self.fc = nn.Linear(16*h2*w2, 2)

    def forward(self, x):
        x = torch.relu(self.bn1(self.conv1(x)))   # (B,16,H,W)
        x, att = self.se1(x)
        x = self.pool1(x); x = self.drop1(x)
        return self.fc(x.flatten(1)), att         # attâ†’(B,16,1,1)

# ========= ä¸»æµç¨‹ =========
curve = {k: [] for k in K_LIST}

for matf in MAT_FILE:
    mdict = loadmat(matf, simplify_cells=True)
    key   = next(k for k in mdict if re.search(r"last_beep$", k, re.I))
    raw   = mdict[key]                             # (2, trials)

    trials, labels = [], []
    for cls, trial_set in enumerate(raw):
        for ep in trial_set:
            sig = preprocess(ep[KEEP_CH_ID])       # (60,T)
            trials.append(sig); labels.append(cls)
    trials  = np.asarray(trials)
    labels  = np.asarray(labels)

    # ç±»åˆ«å‡è¡¡
    i0, i1 = np.where(labels==0)[0], np.where(labels==1)[0]
    m = min(len(i0), len(i1))
    keep = np.sort(np.hstack([i0[:m], i1[:m]]))
    trials, labels = trials[keep], labels[keep]

    # ç²—æ’ CSP
    csp = CSP(2, reg='ledoit_wolf').fit(trials.astype(np.float64), labels)
    score = np.abs(csp.filters_[0]) + np.abs(csp.filters_[-1])
    order = np.argsort(score)[::-1]

    for K in K_LIST:
        sel = order[:K] if K != 60 else order        # 60 æ—¶ç”¨å…¨éƒ¨
        print(f"[{matf.stem}] Top-{K:<2}ï¼š",
              ', '.join(CHAN_NAMES[i] for i in sel))

        # -------- æ„é€ çª—å£æ—¶é¢‘å›¾ --------
        X_win, y_win, g_id = [], [], []
        gid = 0
        for sig, lab in zip(trials[:, sel], labels):
            for w in slide(sig):                    # (K,T) â†’ windows
                X_win.append(to_spec(w))            # (K,F,T')
                y_win.append(lab)
                g_id.append(gid)
            gid += 1

        X_win = np.asarray(X_win)                   # (N, K, F, T')
        K_sel, F_bins, T_bins = X_win.shape[1], X_win.shape[2], X_win.shape[3]

        # reshape â†’ (N,1,H,W) æŠŠ (K,F) åˆå¹¶ä¸ºâ€œé«˜â€
        X_win = X_win.reshape(len(X_win), 1, K_sel*F_bins, T_bins)
        y_win = np.asarray(y_win); g_id = np.asarray(g_id)

        # -------- GroupKFold (10) --------
        acc_fold = []
        gkf = GroupKFold(10)
        for tr, te in gkf.split(X_win, y_win, groups=g_id):
            Xtr = torch.tensor(X_win[tr], dtype=torch.float32, device=DEVICE)
            ytr = torch.tensor(y_win[tr], dtype=torch.long, device=DEVICE)

            Xte = torch.tensor(X_win[te], dtype=torch.float32, device=DEVICE)
            yte = y_win[te]  # â†â˜… åŠ å›è¿™ä¸€è¡Œ
            gte = g_id[te]  # â†â˜… åŠ å›è¿™ä¸€è¡Œ

            net = SpecCNN(img_h=K_sel * F_bins, img_w=T_bins).to(DEVICE)
            opt = torch.optim.Adam(net.parameters(), 2e-3, weight_decay=1e-4)
            lossf = nn.CrossEntropyLoss()

            # ---------- è®­ç»ƒ ----------
            net.train()
            for ep in range(EPOCHS):
                perm = torch.randperm(len(Xtr), device=DEVICE)
                for beg in range(0, len(perm), BATCH):
                    idx = perm[beg:beg + BATCH]
                    logit, _ = net(Xtr[idx])
                    loss = lossf(logit, ytr[idx])
                    opt.zero_grad();
                    loss.backward();
                    opt.step()

            # ---------- æ¨æ–­ ----------
            net.eval();
            preds = []
            with torch.no_grad():
                for beg in range(0, len(Xte), BATCH):
                    sl = slice(beg, beg + BATCH)
                    logits, _ = net(Xte[sl])
                    preds.append(logits.argmax(1).cpu())
            preds = torch.cat(preds).numpy()

            # ---------- trial-level æŠ•ç¥¨ ----------
            vote = {}
            for p, gid_ in zip(preds, gte):
                vote.setdefault(gid_, []).append(p)

            true_trial = {gid_: yte[np.where(gte == gid_)[0][0]]
                          for gid_ in vote}  # â† ç”¨ yte / gte
            acc_fold.append(
                np.mean([max(set(v), key=v.count) == true_trial[gid_]
                         for gid_, v in vote.items()])
            )

        acc_fold_mean = np.mean(acc_fold)
        curve[K].append(acc_fold_mean)  # åˆ«å¿˜è®°å½•

# ========= è¾“å‡º =========
print("\n#Channels |  acc_mean Â± std")
print("---------------------------")
for k in K_LIST:
    arr = np.asarray(curve[k])
    print(f"{k:>9} |  {arr.mean():.3f} Â± {arr.std():.3f}")