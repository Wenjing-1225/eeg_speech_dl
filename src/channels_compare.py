#!/usr/bin/env python
# channels_compare_fbcsp.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Panachakel & Ramakrishnan 2019 imagined short-vs-long å¤çŽ°
#    â€¢ 60-channel baseline (DWT-12 Ã—60)
#    â€¢ å‰ K å¯¹ CSP æ»¤æ³¢å™¨ + DWT-24
#    â€¢ 4-band FB-CSP + TangentSpace + DWT-24  ï¼ˆè®ºæ–‡é…ç½®ï¼‰
#    â€¢ å¯é€‰ SFFS ç‰©ç†é€šé“æŒ‘é€‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import os, warnings, numpy as np, pywt, torch, torch.nn as nn
from pathlib import Path
from scipy.io import loadmat
from scipy.signal import butter, filtfilt, iirnotch
from mne.decoding import CSP
from pyriemann.tangentspace import TangentSpace
from pyriemann.estimation  import Covariances
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score

warnings.filterwarnings("ignore", category=RuntimeWarning)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¼€å…³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
USE_FBCSP = True          # è®ºæ–‡é…ç½®ï¼šFB-CSP + TS + DWT
USE_SFFS  = False         # è‹¥ True è¯·å®žçŽ° run_sffs()
SEED = 0
np.random.seed(SEED); torch.manual_seed(SEED)

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("ðŸ’»  device =", DEVICE)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE      = Path(__file__).resolve().parent.parent
DATA_DIR  = BASE / "data/Short_Long_words"
EOG_CH    = [0, 9, 32, 63]                 # 1,10,33,64
FS, WIN   = 256, 5*256                     # 5 s
# K_LIST    = [0, 1, 3, 5, 7, 9, 11, 13, 15] # 0=60-ch baseline
K_LIST = [0] + list(range(1, 31, 1))
FBANDS    = [(8,12), (12,16), (16,20), (20,24)]
PAIR_DIM_DWT = 24                          # 12 Ã— 2

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ»¤æ³¢å™¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
bp_b, bp_a = butter(4, [8, 70], fs=FS, btype='band')
nb_b, nb_a = iirnotch(60, 30, fs=FS)

def preprocess(sig60):
    sig = filtfilt(bp_b, bp_a,  sig60, axis=1)
    sig = filtfilt(nb_b, nb_a, sig,    axis=1)
    return sig

def bandpass(data, lo, hi):
    b, a = butter(4, [lo, hi], fs=FS, btype='band')
    return filtfilt(b, a, data, axis=-1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DWT-12 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def dwt12(x):
    coeffs = pywt.wavedec(x, "db4", level=4)[:4]   # A4,D4,D3,D2
    feat = []
    for arr in coeffs:
        rms  = np.sqrt((arr**2).mean())
        var  = arr.var()
        p    = (arr**2)/(arr**2).sum()
        ent  = -(p*np.log(p+1e-12)).sum()
        feat.extend([rms, var, ent])
    return np.asarray(feat, np.float32)            # (12,)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DNN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class DNN(nn.Module):
    def __init__(self, d_in):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(d_in, 40), nn.ReLU(), nn.BatchNorm1d(40), nn.Dropout(.10),
            nn.Linear(40, 40),   nn.ReLU(), nn.BatchNorm1d(40), nn.Dropout(.30),
            nn.Linear(40, 40),   nn.Tanh(), nn.BatchNorm1d(40), nn.Dropout(.30),
            nn.Linear(40, 40),   nn.ReLU(), nn.BatchNorm1d(40), nn.Dropout(.30),
            nn.Linear(40, 1))
    def forward(self, x): return self.net(x).squeeze(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ (å ä½) SFFS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_sffs(X60, y, k=15):
    """ç¤ºä¾‹ï¼šç›´æŽ¥è¿”å›žå‰ k ä¸ªé€šé“ï¼›å¦‚éœ€çœŸæ­£ SFFS è¯·è‡ªè¡Œæ›¿æ¢"""
    return list(range(k))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
subj_files = sorted([f for f in DATA_DIR.glob("*.mat") if "_8s" not in f.name])
results = {k: [] for k in K_LIST}

for fmat in subj_files:
    mat = loadmat(fmat, simplify_cells=True)
    key = next(k for k in mat if k.endswith("last_beep"))
    raw = mat[key]                                   # (2, trials)

    # â€”â€”é¢„å¤„ç†â€”â€”
    X, y = [], []
    for cls, row in enumerate(raw):
        for ep in row:
            sig = preprocess(np.delete(ep[:, :WIN], EOG_CH, 0))  # 60Ã—1280
            X.append(sig); y.append(cls)
    X = np.stack(X); y = np.asarray(y, float)

    # â€”â€”ç±»å‡è¡¡â€”â€”
    n0, n1 = (y == 0).sum(), (y == 1).sum()
    if n0 != n1:
        n_min = min(n0, n1)
        keep0 = np.random.choice(np.where(y == 0)[0], n_min, False)
        keep1 = np.random.choice(np.where(y == 1)[0], n_min, False)
        keep  = np.sort(np.hstack([keep0, keep1]))
        X, y  = X[keep], y[keep]

    # â€”â€”SFFSï¼ˆå¯é€‰ï¼‰â€”â€”
    if USE_SFFS:
        sel = run_sffs(X, y, k=15)   # è¿”å›ž â‰¤15 ä¸ªé€šé“ç´¢å¼•
        X   = X[:, sel]

    # ========== é€ K è®¡ç®— ==========
    for K in K_LIST:
        feats_trial = []             # per-trial ç‰¹å¾åˆ—è¡¨

        if K == 0:                   # â€”â€”60-ch baselineâ€”â€”
            pair_dim, pair_num = 12, X.shape[1]
            for ep in X:
                feats_trial.append(np.stack([dwt12(ch) for ch in ep]))

        else:                        # â€”â€”å…ˆå– CSP K å¯¹â€”â€”
            csp = CSP(2*K, reg='ledoit_wolf', transform_into='csp_space').fit(X, y)
            Wmax, Wmin = csp.filters_[:K], csp.filters_[-K:]

            if USE_FBCSP:            # ---- FB-CSP + TS + DWT ----
                ts_bands = []
                for lo, hi in FBANDS:
                    Xfb = bandpass(X, lo, hi)
                    csp_fb = CSP(2*K, reg='ledoit_wolf',
                                  transform_into='csp_space').fit(Xfb, y)
                    covs   = Covariances(estimator='oas').transform(
                             np.tensordot(csp_fb.filters_[:K], Xfb, axes=(1,1))
                             .transpose(1,0,2))
                    ts_bands.append(TangentSpace().fit_transform(covs))

                ts_dim   = ts_bands[0].shape[1]
                pair_dim = ts_dim*len(FBANDS) + 24*K
                pair_num = 1

                for t, ep in enumerate(X):
                    dwt_pairs = []
                    for i in range(K):
                        a, b = Wmax[i]@ep, Wmin[i]@ep
                        dwt_pairs.append(np.hstack([dwt12(a), dwt12(b)]))
                    feats_trial.append(
                        np.hstack([band[t] for band in ts_bands] + dwt_pairs))

            else:                    # ---- ä»… CSP + DWT-24 ----
                pair_dim, pair_num = 24, K
                for ep in X:
                    pairs=[]
                    for i in range(K):
                        a,b = Wmax[i]@ep, Wmin[i]@ep
                        vec = np.hstack([dwt12(a), dwt12(b)])
                        pairs.append((vec-vec.mean())/(vec.std()+1e-6))
                    feats_trial.append(np.stack(pairs))

        feats_trial = np.asarray(feats_trial)         # (n, pair_num, pair_dim)
        if feats_trial.ndim == 2:                     # baseline æƒ…å†µ
            feats_trial = feats_trial[:, None, :]
            pair_num    = 1
            pair_dim    = feats_trial.shape[-1]

        # --------------- 5-fold CV ---------------
        cv = StratifiedKFold(5, shuffle=True, random_state=SEED)
        acc_fold = []
        for tr, te in cv.split(np.arange(len(feats_trial)), y):
            Xtr = torch.tensor(feats_trial[tr].reshape(-1, pair_dim),
                               dtype=torch.float32, device=DEVICE)
            ytr = torch.tensor(np.repeat(y[tr], pair_num),
                               dtype=torch.float32, device=DEVICE)

            Xte = torch.tensor(feats_trial[te].reshape(-1, pair_dim),
                               dtype=torch.float32, device=DEVICE)
            split_te = [pair_num]*len(te)

            net  = DNN(pair_dim).to(DEVICE)
            opt  = torch.optim.Adam(net.parameters(), 1e-3, weight_decay=1e-4)
            loss = nn.BCEWithLogitsLoss()

            for _ in range(50):
                net.train()
                perm = torch.randperm(len(Xtr), device=DEVICE)
                for beg in range(0, len(perm), 512):
                    idx = perm[beg:beg+512]
                    opt.zero_grad()
                    loss(net(Xtr[idx]), ytr[idx]).backward()
                    opt.step()

            net.eval()
            with torch.no_grad():
                prob = torch.sigmoid(net(Xte)).cpu().numpy()

            pred, cur = [], 0
            for n in split_te:
                pred.append(int(prob[cur:cur+n].mean() > 0.5)); cur += n
            acc_fold.append(accuracy_score(y[te], pred))

        results[K].append(np.mean(acc_fold))
    print("âœ”", fmat.name)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ±‡æ€»è¾“å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\nElectrodes |  acc_mean Â± std")
print("-----------------------------")
for k in K_LIST:
    tag = "60 (all)" if k == 0 else str(k*2).rjust(2)
    m, s = np.mean(results[k]), np.std(results[k])
    print(f"{tag:>10} |  {m:.3f} Â± {s:.3f}")